#!/usr/bin/env python3
"""
Phase 1 Integration Test - Enhanced Feature Logging und Dataset Builder Integration
Fahrplan-Abgleich: Task 16 Completion Test

Tests:
1. Enhanced Feature Prediction Logger
2. Integration mit AI Pattern Strategy
3. BarDatasetBuilder Kompatibilit√§t
4. Complete Phase 1 Workflow
"""

import sys
import os
import time
import logging
from datetime import datetime
from pathlib import Path
import json

# Setup Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def test_enhanced_feature_logger():
    """Test 1: Enhanced Feature Prediction Logger"""
    print("üß™ Test 1: Enhanced Feature Prediction Logger...")
    
    try:
        from ai_indicator_optimizer.logging.enhanced_feature_logger import create_enhanced_feature_logger
        
        print("‚úÖ Enhanced Feature Logger importiert")
        
        # Test verschiedene Rotation-Modi
        for rotation in ["none", "daily", "hourly"]:
            print(f"\\nüìã Testing rotation: {rotation}")
            
            with create_enhanced_feature_logger(
                f"test_logs/phase1_features_{rotation}",
                buffer_size=5,
                rotation=rotation,
                mem_monitoring=True
            ) as logger:
                
                # Simuliere AI Trading-Session
                base_time = int(time.time() * 1e9)
                
                for session in range(3):
                    for entry in range(4):
                        # Verschiedene Zeitstempel f√ºr Rotation-Test
                        if rotation == "hourly":
                            ts = base_time + session * 3600 * 1e9 + entry * 60 * 1e9
                        elif rotation == "daily":
                            ts = base_time + session * 24 * 3600 * 1e9 + entry * 3600 * 1e9
                        else:
                            ts = base_time + (session * 4 + entry) * 60 * 1e9
                        
                        # Simuliere Enhanced Features
                        features = {
                            "open": 1.1000 + session * 0.001 + entry * 0.0001,
                            "close": 1.1005 + session * 0.001 + entry * 0.0001,
                            "rsi_14": 50 + entry * 5,
                            "volatility": 0.001 + entry * 0.0001,
                            "session": session,
                            "entry": entry
                        }
                        
                        # Simuliere AI Prediction
                        prediction = {
                            "action": ["BUY", "SELL", "HOLD"][entry % 3],
                            "confidence": 0.6 + entry * 0.1,
                            "reasoning": f"phase1_test_s{session}_e{entry}"
                        }
                        
                        # Enhanced Scores
                        confidence_score = 0.7 + entry * 0.05
                        risk_score = 0.1 + entry * 0.02
                        market_regime = ["trending", "ranging", "volatile"][entry % 3]
                        
                        # Log mit Enhanced API
                        logger.log_prediction(
                            ts_ns=int(ts),
                            instrument="EUR/USD",
                            features=features,
                            prediction=prediction,
                            confidence_score=confidence_score,
                            risk_score=risk_score,
                            market_regime=market_regime
                        )
                
                # Zeige Enhanced Stats
                stats = logger.get_statistics()
                print(f"üìä {rotation} Enhanced Stats:")
                print(f"   Buffer: {stats['buffer_size']}/{stats['buffer_capacity']}")
                print(f"   Total Entries: {stats['total_entries_logged']}")
                print(f"   Files Created: {stats['total_files_created']}")
                print(f"   Current File: {stats['current_file']}")
                if 'memory_rss_gb' in stats:
                    print(f"   Memory: {stats['memory_rss_gb']:.3f} GB")
        
        print("‚úÖ Enhanced Feature Logger Test erfolgreich!")
        return True
        
    except Exception as e:
        print(f"‚ùå Enhanced Feature Logger Test fehlgeschlagen: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_ai_strategy_integration():
    """Test 2: AI Strategy Integration"""
    print("üß™ Test 2: AI Strategy Integration...")
    
    try:
        # Mock Nautilus Components f√ºr Test
        class MockBar:
            def __init__(self, open_price, high, low, close, volume, timestamp):
                self.open = open_price
                self.high = high
                self.low = low
                self.close = close
                self.volume = volume
                self.ts_init = timestamp
                self.bar_type = MockBarType()
        
        class MockBarType:
            def __init__(self):
                self.instrument_id = "EUR/USD.SIM"
        
        # Test Enhanced Components Import
        from ai_indicator_optimizer.logging.enhanced_feature_logger import create_enhanced_feature_logger
        from ai_indicator_optimizer.dataset.bar_dataset_builder import BarDatasetBuilder
        
        print("‚úÖ Enhanced Components importiert")
        
        # Simuliere AI Strategy Setup
        config = {
            "feature_log_base_path": "test_logs/ai_strategy_integration",
            "log_buffer_size": 8,
            "log_rotation": "daily",
            "log_include_pid": True,
            "log_memory_monitoring": True,
            "dataset_horizon": 3,
            "min_dataset_bars": 5
        }
        
        # Setup Enhanced Components
        feature_logger = create_enhanced_feature_logger(
            base_path=config["feature_log_base_path"],
            buffer_size=config["log_buffer_size"],
            rotation=config["log_rotation"],
            include_pid=config["log_include_pid"],
            mem_monitoring=config["log_memory_monitoring"]
        )
        
        dataset_builder = BarDatasetBuilder(
            horizon=config["dataset_horizon"],
            min_bars=config["min_dataset_bars"],
            include_technical_indicators=True
        )
        
        print("‚úÖ Enhanced Components initialisiert")
        
        # Simuliere Trading-Session
        base_time = int(time.time() * 1e9)
        base_price = 1.1000
        
        print("üìä Simuliere Enhanced Trading-Session...")
        
        for i in range(12):  # 12 Bars f√ºr Dataset Builder
            # Simuliere realistische Forex-Daten
            price_trend = 0.0002 * (i - 6)  # Trend-Komponente
            price_noise = (hash(str(i * 13)) % 1000 - 500) * 0.000001  # Pseudo-Random
            
            price = base_price + price_trend + price_noise
            
            bar = MockBar(
                open_price=price,
                high=price + 0.0003 + abs(price_noise) * 2,
                low=price - 0.0002 - abs(price_noise),
                close=price + 0.0001 + price_noise * 0.5,
                volume=1000 + i * 50 + (hash(str(i)) % 500),
                timestamp=base_time + i * 60 * 1e9  # 1 Minute Bars
            )
            
            # Dataset Builder Update
            dataset_builder.on_bar(bar)
            
            # Simuliere Enhanced Features
            features = {
                "open": float(bar.open),
                "high": float(bar.high),
                "low": float(bar.low),
                "close": float(bar.close),
                "volume": float(bar.volume),
                "price_change": bar.close - bar.open,
                "rsi_14": 50 + (i % 10) * 3,
                "volatility": 0.001 + (i % 5) * 0.0002,
                "bar_index": i
            }
            
            # Simuliere AI Prediction
            prediction = {
                "action": ["BUY", "SELL", "HOLD"][i % 3],
                "confidence": 0.6 + (i % 4) * 0.1,
                "reasoning": f"integration_test_bar_{i}"
            }
            
            # Enhanced Scores
            confidence_score = 0.7 + (i % 3) * 0.05
            risk_score = 0.1 + (i % 4) * 0.02
            market_regime = ["trending", "ranging", "volatile"][i % 3]
            
            # Enhanced Feature Logging
            feature_logger.log_prediction(
                ts_ns=bar.ts_init,
                instrument=str(bar.bar_type.instrument_id),
                features=features,
                prediction=prediction,
                confidence_score=confidence_score,
                risk_score=risk_score,
                market_regime=market_regime
            )
            
            if i % 4 == 0:
                print(f"   Bar {i+1}: {prediction['action']} @ {confidence_score:.2f} ({market_regime})")
        
        # Zeige Enhanced Statistiken
        logger_stats = feature_logger.get_statistics()
        dataset_stats = dataset_builder.get_stats()
        
        print(f"üìä Enhanced Integration Stats:")
        print(f"   Feature Logger Entries: {logger_stats['total_entries_logged']}")
        print(f"   Dataset Builder Entries: {dataset_stats['total_entries']}")
        print(f"   Label Distribution: {dataset_stats['label_distribution']}")
        print(f"   Memory Usage: {logger_stats.get('memory_rss_gb', 0):.3f} GB")
        
        # Export Dataset
        dataset_path = "test_logs/phase1_integration_dataset.parquet"
        if dataset_builder.to_parquet(dataset_path, include_metadata=True):
            print(f"‚úÖ Dataset exportiert: {dataset_path}")
        
        # Cleanup
        feature_logger.close()
        
        print("‚úÖ AI Strategy Integration Test erfolgreich!")
        return True
        
    except Exception as e:
        print(f"‚ùå AI Strategy Integration Test fehlgeschlagen: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_complete_phase1_workflow():
    """Test 3: Complete Phase 1 Workflow"""
    print("üß™ Test 3: Complete Phase 1 Workflow...")
    
    try:
        from ai_indicator_optimizer.logging.enhanced_feature_logger import create_enhanced_feature_logger
        from ai_indicator_optimizer.dataset.bar_dataset_builder import BarDatasetBuilder
        
        print("‚úÖ Phase 1 Components verf√ºgbar")
        
        # Simuliere komplette Phase 1 Pipeline
        print("üìä Simuliere Complete Phase 1 Workflow...")
        
        # Multi-Instrument Test
        instruments = ["EUR/USD", "GBP/USD", "USD/JPY"]
        
        with create_enhanced_feature_logger(
            "test_logs/complete_phase1_workflow",
            buffer_size=10,
            rotation="hourly",
            mem_monitoring=True
        ) as logger:
            
            builders = {}
            for instrument in instruments:
                builders[instrument] = BarDatasetBuilder(
                    horizon=2,
                    min_bars=3,
                    include_technical_indicators=True
                )
            
            base_time = int(time.time() * 1e9)
            
            # Simuliere Multi-Instrument Trading
            for session in range(8):
                for i, instrument in enumerate(instruments):
                    # Verschiedene Preise pro Instrument
                    if instrument == "EUR/USD":
                        base_price = 1.1000
                    elif instrument == "GBP/USD":
                        base_price = 1.2500
                    else:  # USD/JPY
                        base_price = 150.00
                    
                    # Mock Bar
                    class MockBar:
                        def __init__(self, instrument, price, session_id):
                            self.open = price
                            self.high = price + 0.0003
                            self.low = price - 0.0002
                            self.close = price + 0.0001
                            self.volume = 1000 + session_id * 100
                            self.ts_init = base_time + session_id * 300 * 1e9 + i * 60 * 1e9
                            self.bar_type = type('MockBarType', (), {'instrument_id': instrument})()
                    
                    price = base_price + session * 0.001 + (hash(str(session * i)) % 100) * 0.00001
                    bar = MockBar(instrument, price, session)
                    
                    # Dataset Builder Update
                    builders[instrument].on_bar(bar)
                    
                    # Enhanced Features
                    features = {
                        "open": bar.open,
                        "close": bar.close,
                        "volume": bar.volume,
                        "session": session,
                        "instrument_index": i
                    }
                    
                    # AI Prediction
                    prediction = {
                        "action": ["BUY", "SELL", "HOLD"][(session + i) % 3],
                        "confidence": 0.6 + (session % 3) * 0.1,
                        "reasoning": f"phase1_workflow_{instrument}_s{session}"
                    }
                    
                    # Enhanced Logging
                    logger.log_prediction(
                        ts_ns=bar.ts_init,
                        instrument=instrument,
                        features=features,
                        prediction=prediction,
                        confidence_score=0.7 + (session % 2) * 0.1,
                        risk_score=0.1 + (i % 3) * 0.05,
                        market_regime=["trending", "ranging"][session % 2]
                    )
            
            # Final Stats
            final_stats = logger.get_statistics()
            print(f"üìä Complete Phase 1 Workflow Stats:")
            print(f"   Total Entries: {final_stats['total_entries_logged']}")
            print(f"   Files Created: {final_stats['total_files_created']}")
            print(f"   Buffer Usage: {final_stats['buffer_usage_pct']:.1f}%")
            
            # Export alle Datasets
            for instrument, builder in builders.items():
                dataset_path = f"test_logs/phase1_{instrument.replace('/', '_')}_dataset.parquet"
                if builder.to_parquet(dataset_path):
                    stats = builder.get_stats()
                    print(f"   {instrument} Dataset: {stats['total_entries']} entries")
        
        print("‚úÖ Complete Phase 1 Workflow Test erfolgreich!")
        return True
        
    except Exception as e:
        print(f"‚ùå Complete Phase 1 Workflow Test fehlgeschlagen: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Phase 1 Integration Test Suite"""
    print("üöÄ Phase 1 Integration Test Suite")
    print("Task 16: Enhanced Feature Logging und Dataset Builder Integration")
    print("=" * 80)
    
    # Erstelle Test-Verzeichnisse
    Path("test_logs").mkdir(exist_ok=True)
    
    success = True
    
    # Test 1: Enhanced Feature Logger
    print("\\nüìã Test 1: Enhanced Feature Prediction Logger")
    if not test_enhanced_feature_logger():
        success = False
    
    # Test 2: AI Strategy Integration
    print("\\nüìã Test 2: AI Strategy Integration")
    if not test_ai_strategy_integration():
        success = False
    
    # Test 3: Complete Phase 1 Workflow
    print("\\nüìã Test 3: Complete Phase 1 Workflow")
    if not test_complete_phase1_workflow():
        success = False
    
    print("\\n" + "=" * 80)
    
    if success:
        print("üéâ Phase 1 Integration Tests erfolgreich!")
        print("\\nüìä Generierte Phase 1 Dateien:")
        
        # Zeige alle generierten Dateien
        import glob
        
        parquet_files = glob.glob("test_logs/*.parquet")
        json_files = glob.glob("test_logs/*.json")
        
        total_size = 0
        print("\\nüìÅ Enhanced Feature Logs:")
        for f in sorted(parquet_files):
            if "features" in f:
                size = Path(f).stat().st_size
                total_size += size
                print(f"  ‚úÖ {f} ({size:,} bytes)")
        
        print("\\nüìÅ Dataset Exports:")
        for f in sorted(parquet_files):
            if "dataset" in f:
                size = Path(f).stat().st_size
                total_size += size
                print(f"  ‚úÖ {f} ({size:,} bytes)")
        
        print("\\nüìÅ Metadata Files:")
        for f in sorted(json_files):
            size = Path(f).stat().st_size
            total_size += size
            print(f"  ‚úÖ {f} ({size:,} bytes)")
        
        print(f"\\nüìä Gesamt-Dateigr√∂√üe: {total_size:,} bytes")
        
        print("\\nüéØ Phase 1 Foundation Enhancement ABGESCHLOSSEN:")
        print("  ‚úÖ Enhanced Feature Prediction Logger (Production-Ready)")
        print("  ‚úÖ AI Strategy Integration (Enhanced API)")
        print("  ‚úÖ BarDatasetBuilder Kompatibilit√§t")
        print("  ‚úÖ Multi-Process-Safety mit PID")
        print("  ‚úÖ Schema-Drift-Protection")
        print("  ‚úÖ Memory-Monitoring")
        print("  ‚úÖ Automatische Rotation (daily/hourly)")
        print("  ‚úÖ Complete Phase 1 Workflow")
        
        print("\\nüöÄ FAHRPLAN-STATUS: Phase 1 ‚úÖ ABGESCHLOSSEN")
        print("   N√§chste Phase: Phase 2 - Enhanced Pattern Recognition (Task 8)")
        
    else:
        print("‚ùå Phase 1 Integration Tests fehlgeschlagen!")
        return 1
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)